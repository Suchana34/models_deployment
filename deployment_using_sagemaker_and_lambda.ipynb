{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deployment_using_sagemaker_and_lambda.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRsL13CDMuer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import boto3\n",
        "import re\n",
        "from sagemaker import get_execution_role\n",
        "\n",
        "role = get_execution_role()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "bucket='Your_S3_Bucket'\n",
        "data_key = 'Your_dataset.csv'\n",
        "data_location = 's3://{}/{}'.format(bucket, data_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucuOfdKgZkN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import time\n",
        "import json\n",
        "import sagemaker.amazon.common as smac\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC8MGt4RZqky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(data_location)\n",
        "\n",
        "\n",
        "data.to_csv(\"data.csv\", sep=',', index=False)\n",
        "\n",
        "# print the shape of the data file\n",
        "print(data.shape)\n",
        "\n",
        "# show the top few rows\n",
        "display(data.head())\n",
        "\n",
        "# describe the data object\n",
        "display(data.describe())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHErJoK2ZqhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rand_split = np.random.rand(len(data))\n",
        "train_list = rand_split < 0.8\n",
        "val_list = (rand_split >= 0.8) & (rand_split < 0.9)\n",
        "test_list = rand_split >= 0.9\n",
        "\n",
        "data_train = data[train_list]\n",
        "data_val = data[val_list]\n",
        "data_test = data[test_list]\n",
        "\n",
        "train_y = ((data_train.iloc[:,6])).as_matrix();\n",
        "train_X = (data_train.iloc[:,1:6]).as_matrix();\n",
        "\n",
        "\n",
        "\n",
        "# train_y = ((data_train.iloc[:,1] == 'M') +0).as_matrix();\n",
        "# train_X = data_train.iloc[:,2:].as_matrix();\n",
        "\n",
        "val_y = ((data_val.iloc[:,6]).as_matrix())\n",
        "val_X = data_val.iloc[:,1:6].as_matrix()\n",
        "\n",
        "test_y = ((data_test.iloc[:,6]).as_matrix())\n",
        "test_X = data_test.iloc[:,1:6].as_matrix()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWCrbShvZqfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = 'linear_train.data'\n",
        "\n",
        "f = io.BytesIO()\n",
        "smac.write_numpy_to_dense_tensor(f, train_X.astype('float32'), train_y.astype('float32'))\n",
        "f.seek(0)\n",
        "\n",
        "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', train_file)).upload_fileobj(f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjmTrgtEZqZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_file = 'linear_validation.data'\n",
        "\n",
        "f = io.BytesIO()\n",
        "smac.write_numpy_to_dense_tensor(f, val_X.astype('float32'), val_y.astype('float32'))\n",
        "f.seek(0)\n",
        "\n",
        "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation', validation_file)).upload_fileobj(f)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSzv2L2LfImq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ---\n",
        "# ## Train\n",
        "# \n",
        "# Now we can begin to specify our linear model.  Amazon SageMaker's Linear Learner actually fits many models in parallel, each with slightly different hyperparameters, and then returns the one with the best fit.  This functionality is automatically enabled.  We can influence this using parameters like:\n",
        "# \n",
        "# - `num_models` to increase to total number of models run.  The specified parameters will always be one of those models, but the algorithm also chooses models with nearby parameter values in order to find a solution nearby that may be more optimal.  In this case, we're going to use the max of 32.\n",
        "# - `loss` which controls how we penalize mistakes in our model estimates.  For this case, let's use absolute loss as we haven't spent much time cleaning the data, and absolute loss will be less sensitive to outliers.\n",
        "# - `wd` or `l1` which control regularization.  Regularization can prevent model overfitting by preventing our estimates from becoming too finely tuned to the training data, which can actually hurt generalizability.  In this case, we'll leave these parameters as their default \"auto\" though.\n",
        "\n",
        "# ### Specify container images used for training and hosting SageMaker's linear-learner\n",
        "\n",
        "\n",
        "\n",
        "# See 'Algorithms Provided by Amazon SageMaker: Common Parameters' in the SageMaker documentation for an explanation of these values.\n",
        "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
        "container = get_image_uri(boto3.Session().region_name, 'linear-learner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inlJSKh5fIsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear_job = 'DEMO-linear-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
        "\n",
        "\n",
        "\n",
        "print(\"Job name is:\", linear_job)\n",
        "\n",
        "linear_training_params = {\n",
        "    \"RoleArn\": role,\n",
        "    \"TrainingJobName\": linear_job,\n",
        "    \"AlgorithmSpecification\": {\n",
        "        \"TrainingImage\": container,\n",
        "        \"TrainingInputMode\": \"File\"\n",
        "    },\n",
        "    \"ResourceConfig\": {\n",
        "        \"InstanceCount\": 1,\n",
        "        \"InstanceType\": \"ml.c4.2xlarge\",\n",
        "        \"VolumeSizeInGB\": 10\n",
        "    },\n",
        "    \"InputDataConfig\": [\n",
        "        {\n",
        "            \"ChannelName\": \"train\",\n",
        "            \"DataSource\": {\n",
        "                \"S3DataSource\": {\n",
        "                    \"S3DataType\": \"S3Prefix\",\n",
        "                    \"S3Uri\": \"s3://{}/{}/train/\".format(bucket, prefix),\n",
        "                    \"S3DataDistributionType\": \"ShardedByS3Key\"\n",
        "                }\n",
        "            },\n",
        "            \"CompressionType\": \"None\",\n",
        "            \"RecordWrapperType\": \"None\"\n",
        "        },\n",
        "        {\n",
        "            \"ChannelName\": \"validation\",\n",
        "            \"DataSource\": {\n",
        "                \"S3DataSource\": {\n",
        "                    \"S3DataType\": \"S3Prefix\",\n",
        "                    \"S3Uri\": \"s3://{}/{}/validation/\".format(bucket, prefix),\n",
        "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
        "                }\n",
        "            },\n",
        "            \"CompressionType\": \"None\",\n",
        "            \"RecordWrapperType\": \"None\"\n",
        "        }\n",
        "\n",
        "    ],\n",
        "    \"OutputDataConfig\": {\n",
        "        \"S3OutputPath\": \"s3://{}/{}/\".format(bucket, prefix)\n",
        "    },\n",
        "    \"HyperParameters\": {\n",
        "        \"feature_dim\": \"5\",\n",
        "        \"mini_batch_size\": \"100\",\n",
        "        \"predictor_type\": \"regressor\",\n",
        "        \"epochs\": \"10\",\n",
        "        \"num_models\": \"32\",\n",
        "        \"loss\": \"absolute_loss\"\n",
        "    },\n",
        "    \"StoppingCondition\": {\n",
        "        \"MaxRuntimeInSeconds\": 60 * 60\n",
        "    }\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdxz32pAfIpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Now let's kick off our training job in SageMaker's distributed, managed training, using the parameters we just created.  Because training is managed, we don't have to wait for our job to finish to continue, but for this case, let's use boto3's 'training_job_completed_or_stopped' waiter so we can ensure that the job has been started.\n",
        "\n",
        "get_ipython().run_cell_magic('time', '', \"\\nregion = boto3.Session().region_name\\nsm = boto3.client('sagemaker')\\n\\nsm.create_training_job(**linear_training_params)\\n\\nstatus = sm.describe_training_job(TrainingJobName=linear_job)['TrainingJobStatus']\\nprint(status)\\nsm.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=linear_job)\\nif status == 'Failed':\\n    message = sm.describe_training_job(TrainingJobName=linear_job)['FailureReason']\\n    print('Training failed with the following error: {}'.format(message))\\n    raise Exception('Training job failed')\")\n",
        "\n",
        "\n",
        "# ---\n",
        "# ## Host\n",
        "# \n",
        "# Now that we've trained the linear algorithm on our data, let's setup a model which can later be hosted.  We will:\n",
        "# 1. Point to the scoring container\n",
        "# 1. Point to the model.tar.gz that came from training\n",
        "# 1. Create the hosting model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSsybIusfIk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear_hosting_container = {\n",
        "    'Image': container,\n",
        "    'ModelDataUrl': sm.describe_training_job(TrainingJobName=linear_job)['ModelArtifacts']['S3ModelArtifacts']\n",
        "}\n",
        "\n",
        "create_model_response = sm.create_model(\n",
        "    ModelName=linear_job,\n",
        "    ExecutionRoleArn=role,\n",
        "    PrimaryContainer=linear_hosting_container)\n",
        "\n",
        "print(create_model_response['ModelArn'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjG15zuefr9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Once we've setup a model, we can configure what our hosting endpoints should be.  Here we specify:\n",
        "# 1. EC2 instance type to use for hosting\n",
        "# 1. Initial number of instances\n",
        "# 1. Our hosting model name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApTr74TQfsDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear_endpoint_config = 'DEMO-linear-endpoint-config-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
        "print(linear_endpoint_config)\n",
        "create_endpoint_config_response = sm.create_endpoint_config(\n",
        "    EndpointConfigName=linear_endpoint_config,\n",
        "    ProductionVariants=[{\n",
        "        'InstanceType': 'ml.t2.medium',\n",
        "        'InitialInstanceCount': 1,\n",
        "        'ModelName': linear_job,\n",
        "        'VariantName': 'AllTraffic'}])\n",
        "\n",
        "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGww7omafsAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now that we've specified how our endpoint should be configured, we can create them.  This can be done in the background, but for now let's run a loop that updates us on the status of the endpoints so that we know when they are ready for use.\n",
        "\n",
        "\n",
        "\n",
        "get_ipython().run_cell_magic('time', '', '\\nlinear_endpoint = \\'DEMO-linear-endpoint-\\' + time.strftime(\"%Y%m%d%H%M\", time.gmtime())\\nprint(linear_endpoint)\\ncreate_endpoint_response = sm.create_endpoint(\\n    EndpointName=linear_endpoint,\\n    EndpointConfigName=linear_endpoint_config)\\nprint(create_endpoint_response[\\'EndpointArn\\'])\\n\\nresp = sm.describe_endpoint(EndpointName=linear_endpoint)\\nstatus = resp[\\'EndpointStatus\\']\\nprint(\"Status: \" + status)\\n\\nsm.get_waiter(\\'endpoint_in_service\\').wait(EndpointName=linear_endpoint)\\n\\nresp = sm.describe_endpoint(EndpointName=linear_endpoint)\\nstatus = resp[\\'EndpointStatus\\']\\nprint(\"Arn: \" + resp[\\'EndpointArn\\'])\\nprint(\"Status: \" + status)\\n\\nif status != \\'InService\\':\\n    raise Exception(\\'Endpoint creation did not succeed\\')')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFTmc3Qwfr7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ## Predict\n",
        "# ### Predict on Test Data\n",
        "# \n",
        "# Now that we have our hosted endpoint, we can generate statistical predictions from it.  Let's predict on our test dataset to understand how accurate our model is.\n",
        "# \n",
        "# There are many metrics to measure classification accuracy.  Common examples include include:\n",
        "# - Precision\n",
        "# - Recall\n",
        "# - F1 measure\n",
        "# - Area under the ROC curve - AUC\n",
        "# - Total Classification Accuracy \n",
        "# - Mean Absolute Error\n",
        "# \n",
        "# For our example, we'll keep things simple and use total classification accuracy as our metric of choice. We will also evaluate  Mean Absolute  Error (MAE) as the linear-learner has been optimized using this metric, not necessarily because it is a relevant metric from an application point of view. We'll compare the performance of the linear-learner against a naive benchmark prediction which uses majority class observed in the training data set for prediction on the test data.\n",
        "# \n",
        "# \n",
        "# \n",
        "\n",
        "# ### Function to convert an array to a csv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSoeZE0rf6A2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def np2csv(arr):\n",
        "    csv = io.BytesIO()\n",
        "    np.savetxt(csv, arr, delimiter=',', fmt='%g')\n",
        "    return csv.getvalue().decode().rstrip()\n",
        "\n",
        "\n",
        "# Next, we'll invoke the endpoint to get predictions."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaLdxzEbf6ES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "runtime= boto3.client('runtime.sagemaker')\n",
        "\n",
        "payload = np2csv(test_X)\n",
        "response = runtime.invoke_endpoint(EndpointName=linear_endpoint,\n",
        "                                   ContentType='text/csv',\n",
        "                                   Body=payload)\n",
        "result = json.loads(response['Body'].read().decode())\n",
        "test_pred = np.array([r['score'] for r in result['predictions']])\n",
        "\n",
        "\n",
        "# Let's compare linear learner based mean absolute prediction errors from a baseline prediction which uses majority class to predict every instance.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzUjCRBlf5_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_mae_linear = np.mean(np.abs(test_y - test_pred))\n",
        "test_mae_baseline = np.mean(np.abs(test_y - np.median(train_y))) ## training median as baseline predictor\n",
        "\n",
        "print(\"Test MAE Baseline :\", round(test_mae_baseline, 3))\n",
        "print(\"Test MAE Linear:\", round(test_mae_linear,3))\n",
        "\n",
        "\n",
        "# Let's compare predictive accuracy using a classification threshold of 0.5 for the predicted and compare against the majority class prediction from training data set\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5oUep24gFgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred_class = (test_pred > 0.5)+0;\n",
        "test_pred_baseline = np.repeat(np.median(train_y), len(test_y))\n",
        "\n",
        "prediction_accuracy = np.mean((test_y == test_pred_class))*100\n",
        "baseline_accuracy = np.mean((test_y == test_pred_baseline))*100\n",
        "\n",
        "print(\"Prediction Accuracy:\", round(prediction_accuracy,1), \"%\")\n",
        "print(\"Baseline Accuracy:\", round(baseline_accuracy,1), \"%\")\n",
        "\n",
        "\n",
        "# ###### Run the cell below to delete endpoint once you are done.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paXPpKxhgFmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sm.delete_endpoint(EndpointName=linear_endpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzbKzE-mgFj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E88jqn1IgFe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}