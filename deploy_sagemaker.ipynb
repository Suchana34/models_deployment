{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deploy_sagemaker.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Llg97z7F7_Z",
        "colab_type": "text"
      },
      "source": [
        "Importing Important Libraries\n",
        "\n",
        "Steps To Be Followed\n",
        "\n",
        "Importing necessary Libraries\n",
        "\n",
        "Creating S3 bucket\n",
        "\n",
        "Mapping train And Test Data in S3\n",
        "\n",
        "Mapping The path of the models in S3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOnIF2JeF3OS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sagemaker\n",
        "import boto3\n",
        "from sagemaker.amazon.amazon_estimator import get_image_uri \n",
        "from sagemaker.session import s3_input, Session\n",
        "\n",
        "bucket_name = 'bankapplication' # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n",
        "my_region = boto3.session.Session().region_name # set the region of the instance\n",
        "print(my_region)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9RSbZelJuFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#us-east-1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhZ1ArCOGECX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s3 = boto3.resource('s3')\n",
        "try:\n",
        "    if  my_region == 'us-east-1':\n",
        "        s3.create_bucket(Bucket=bucket_name)\n",
        "    print('S3 bucket created successfully')\n",
        "except Exception as e:\n",
        "    print('S3 error: ',e)\n",
        "\n",
        "    \n",
        "#S3 bucket created successfully\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XQ_9x5CGD_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set an output path where the trained model will be saved\n",
        "prefix = 'xgboost-as-a-built-in-algo'\n",
        "output_path ='s3://{}/{}/output'.format(bucket_name, prefix)\n",
        "print(output_path)\n",
        "\n",
        "#s3://bankapplication/xgboost-as-a-built-in-algo/output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYlTuQjKGD8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Downloading The Dataset And Storing in S3\n",
        "\n",
        "import pandas as pd\n",
        "import urllib\n",
        "try:\n",
        "    urllib.request.urlretrieve (\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", \"bank_clean.csv\")\n",
        "    print('Success: downloaded bank_clean.csv.')\n",
        "except Exception as e:\n",
        "    print('Data load error: ',e)\n",
        "\n",
        "try:\n",
        "    model_data = pd.read_csv('./bank_clean.csv',index_col=0)\n",
        "    print('Success: Data loaded into dataframe.')\n",
        "except Exception as e:\n",
        "    print('Data load error: ',e)\n",
        "\n",
        "\n",
        "# Success: downloaded bank_clean.csv.\n",
        "# Success: Data loaded into dataframe."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc9sODpCGD7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Train Test split\n",
        "\n",
        "import numpy as np\n",
        "train_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data))])\n",
        "print(train_data.shape, test_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgyz3ZQuKJFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Saving Train And Test Into Buckets\n",
        "## We start with Train Data\n",
        "import os\n",
        "pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], \n",
        "                                                axis=1)], \n",
        "                                                axis=1).to_csv('train.csv', index=False, header=False)\n",
        "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
        "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP17bGJCKJJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test Data Into Buckets\n",
        "pd.concat([test_data['y_yes'], test_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('test.csv', index=False, header=False)\n",
        "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')\n",
        "s3_input_test = sagemaker.s3_input(s3_data='s3://{}/{}/test'.format(bucket_name, prefix), content_type='csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_17wdK_WKJD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Building Models Xgboot- Inbuilt Algorithm\n",
        "\n",
        "\n",
        "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
        "# specify the repo_version depending on your preference.\n",
        "container = get_image_uri(boto3.Session().region_name,\n",
        "                          'xgboost', \n",
        "                          repo_version='1.0-1')\n",
        "\n",
        "\n",
        "#finish training the rest of the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMfiLGuZKepx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Deploy Machine Learning Model As Endpoints\n",
        "\n",
        "xgb_predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXP5m-6LKevt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prediction of the Test Data\n",
        "\n",
        "from sagemaker.predictor import csv_serializer\n",
        "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #load the data into an array\n",
        "xgb_predictor.content_type = 'text/csv' # set the data type for an inference\n",
        "xgb_predictor.serializer = csv_serializer # set the serializer type\n",
        "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
        "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
        "print(predictions_array.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhmQYsaiKeso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQubyjCMKeoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
        "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]; p = (tp+tn)/(tp+tn+fp+fn)*100\n",
        "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
        "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
        "print(\"Observed\")\n",
        "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
        "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OvvV-ORM80D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Deleting The Endpoints\n",
        "\n",
        "\n",
        "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
        "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
        "bucket_to_delete.objects.all().delete()\n",
        "\n",
        "\n",
        "\n",
        "# Out[32]:\n",
        "# [{'ResponseMetadata': {'RequestId': '2FF829102DC6DFD1',\n",
        "#    'HostId': 'mYPqeWyx3REoLIsQu2MVorzKLrlxES2n6Dcdr3PycVf1VkRCxicEewoPP8IxRguc5MGksLnjynY=',\n",
        "#    'HTTPStatusCode': 200,\n",
        "#    'HTTPHeaders': {'x-amz-id-2': 'mYPqeWyx3REoLIsQu2MVorzKLrlxES2n6Dcdr3PycVf1VkRCxicEewoPP8IxRguc5MGksLnjynY=',\n",
        "#     'x-amz-request-id': '2FF829102DC6DFD1',\n",
        "#     'date': 'Sat, 29 Aug 2020 10:21:27 GMT',\n",
        "#     'connection': 'close',\n",
        "#     'content-type': 'application/xml',\n",
        "#     'transfer-encoding': 'chunked',\n",
        "#     'server': 'AmazonS3'},\n",
        "#    'RetryAttempts': 0},\n",
        "#   'Deleted': [{'Key': 'xgboost-as-a-built-in-algo/train/train.csv'},\n",
        "#    {'Key': 'xgboost-as-a-built-in-algo/test/test.csv'},\n",
        "#    {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2020-08-29-09-49-29-015/output/model.tar.gz'}]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acSy8EcmM8Pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eTl-01rM8Nz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}